{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#bem-vindo-ao-meu-portfolio","title":"Bem-vindo ao meu Portf\u00f3lio! \ud83d\udc77\u200d\u2642\ufe0f","text":"<p>Me chamo <code>Tiago Linhares</code>, sou Analista de Dados Senior migrando para Engenharia de Dados.</p> <p>Sou uma pessoa curiosa e com muita vontade de aprender. Gosto de desafios, resolver problemas e criar solu\u00e7\u00f5es.</p> <p>Aqui voc\u00ea encontrar\u00e1 um pouco sobre mim, meus projetos e artigos sobre dados.</p>"},{"location":"#habilidades-tecnicas","title":"Habilidades T\u00e9cnicas","text":"<ul> <li> <p>Linguagens de Programa\u00e7\u00e3o:  </p> </li> <li> <p>Ferramentas de ELT:  </p> </li> <li> <p>Banco de Dados:  </p> </li> <li> <p>BI:  </p> </li> <li> <p>Virtualiza\u00e7\u00e3o:  </p> </li> <li> <p>Sistema Preferido: </p> </li> <li> <p>Cloud e Infraestrutura: </p> </li> </ul>"},{"location":"#projetos-destacados","title":"Projetos Destacados","text":"<ul> <li>Athena Stack Infra: Infraestrutura de dados robusta utilizando Airflow, DBT e outras ferramentas.</li> <li>Curso SQL: Curso completo de SQL para analistas de dados.</li> </ul>"},{"location":"#publicacoes","title":"Publica\u00e7\u00f5es","text":"<ul> <li>Guia para se Tornar um Analista de Dados: Livro focado em guiar a trajet\u00f3rioa de analistas de dados.</li> </ul>"},{"location":"projetos/","title":"Projetos","text":""},{"location":"projetos/#projetos-de-dados","title":"Projetos de Dados \ud83d\udc77\u200d\u2642\ufe0f","text":"<p>Abaixo voc\u00ea encontra uma lista dos meus projetos de dados que desenvolvi, para aplicar meus conhecimentos e ajudar a comunidade de dados.</p>"},{"location":"projetos/#projeto-zero-inadimplencia","title":"Projeto Zero Inadimpl\u00eancia","text":""},{"location":"projetos/#objetivo","title":"Objetivo","text":"<p>Projeto focado em reduzir a inadimpl\u00eancia de uma empresa, utilizando dados para identificar padr\u00f5es e criar solu\u00e7\u00f5es.</p>"},{"location":"projetos/#tecnologias-utilizadas","title":"Tecnologias Utilizadas","text":""},{"location":"projetos/#projeto-athena-stack-de-dados","title":"Projeto Athena - Stack de dados","text":""},{"location":"projetos/#objetivo_1","title":"Objetivo","text":"<p>Evoluir a stack de dados em excel que \u00e9 como a empresa trabalha atualmente, para uma stack de dados moderna e escal\u00e1vel.</p>"},{"location":"projetos/#tecnologias-utilizadas_1","title":"Tecnologias Utilizadas","text":""},{"location":"projetos/#curso-sql","title":"Curso SQL","text":""},{"location":"projetos/#objetivo_2","title":"Objetivo","text":"<p>Ensinar SQL do b\u00e1sico ao avan\u00e7ado, com exemplos pr\u00e1ticos e exerc\u00edcios.</p>"},{"location":"projetos/#tecnologias-utilizadas_2","title":"Tecnologias Utilizadas","text":""},{"location":"projetos/#sql-anti-padroes","title":"Sql Anti Padr\u00f5es","text":""},{"location":"projetos/#objetivo_3","title":"Objetivo","text":"<p>Destacar pr\u00e1ticas comuns, mas ineficientes, em SQL e como corrigi-las. \u00c9 destinado a desenvolvedores que est\u00e3o aprendendo a otimizar suas consultas.</p>"},{"location":"projetos/#tecnologias-utilizadas_3","title":"Tecnologias Utilizadas","text":""},{"location":"projetos/#desafio-sql-30-dias","title":"Desafio SQL 30 dias","text":""},{"location":"projetos/#objetivo_4","title":"Objetivo","text":"<p>Desafio de 30 dias para aprender SQL, com exemplos pr\u00e1ticos e exerc\u00edcios.</p>"},{"location":"projetos/#tecnologias-utilizadas_4","title":"Tecnologias Utilizadas","text":""},{"location":"projetos/#adventure-project","title":"Adventure Project","text":""},{"location":"projetos/#objetivo_5","title":"Objetivo","text":"<p>Projeto de dados para simular um ambiente de uma empresa fict\u00edcia, com dados de vendas, financeiro, marketing e opera\u00e7\u00f5es.</p>"},{"location":"projetos/#tecnologias-utilizadas_5","title":"Tecnologias Utilizadas","text":""},{"location":"projetos/#projeto-covid-19","title":"Projeto - COVID-19","text":""},{"location":"projetos/#objetivo_6","title":"Objetivo","text":"<p>Projeto de dados para analisar os dados da COVID-19 no Brasil.</p>"},{"location":"projetos/#tecnologias-utilizadas_6","title":"Tecnologias Utilizadas","text":""},{"location":"projetos/#projeto-robo-envio-de-alertas-telegram","title":"Projeto - Rob\u00f4 envio de alertas Telegram","text":""},{"location":"projetos/#objetivo_7","title":"Objetivo","text":"<p>Projeto de dados para ler e analisar e-mails para poder enviar alertas de dados para um grupo no Telegram.</p>"},{"location":"projetos/#tecnologias-utilizadas_7","title":"Tecnologias Utilizadas","text":""},{"location":"projetos/#projeto-sql-database-specialist","title":"Projeto - SQL Database Specialist","text":""},{"location":"projetos/#objetivo_8","title":"Objetivo","text":"<p>Projeto de dados para modelar um banco de dados de empresas fict\u00edcias, para aplicar os conceitos de modelagem de dados.</p>"},{"location":"projetos/#tecnologias-utilizadas_8","title":"Tecnologias Utilizadas","text":""},{"location":"projetos/athena_stack/","title":"Projeto Athena - Evolu\u00e7\u00e3o de uma Stack de Dados \ud83e\uddd9\u200d\u2642\ufe0f","text":"<p>S\u00e9rie completa aqui</p>"},{"location":"projetos/athena_stack/#descricao","title":"Descri\u00e7\u00e3o","text":"<p>O Projeto Athena \u00e9 um projeto de evolu\u00e7\u00e3o de uma stack de dados, que tem como objetivo demonstrar as habilidades de <code>Engenharia de Dados</code>, <code>DataOps</code>, <code>Arquitetura de Dados</code> e <code>Orquestra\u00e7\u00e3o de Pipelines</code>.</p> <p>Esse \u00e9 um projeto inovador e desafiador, que aborda conceitos e tecnologias avan\u00e7adas de Engenharia de Dados, e tem como objetivo capacitar profissionais de dados a construir e evoluir stacks de dados eficientes e escal\u00e1veis.</p>"},{"location":"projetos/athena_stack/#ciclo-de-vida-da-engenharia-de-dados","title":"Ciclo de vida da Engenharia de Dados","text":"Elemento Descri\u00e7\u00e3o Seguran\u00e7a Controle de acesso para dadosSistemas Gerenciamento de dados Governan\u00e7a de dadosCapacidade de dadosAccountabilityModelagem de dadosIntegridade dos dados DataOps Governan\u00e7a de dadosObservabilidade e monitoramentoRelat\u00f3rios de incidentes Arquitetura de dados An\u00e1lise de dadosDesenvolvimentoPlataforma de dadosGerar valor para dados Orquestra\u00e7\u00e3o Coordenar fluxos de trabalhoPrograma\u00e7\u00e3oExecutar tarefas Engenharia de software Habilidades de programarPrototipa\u00e7\u00e3oGest\u00e3o de c\u00f3digoTeste e recupera\u00e7\u00e3o"},{"location":"projetos/athena_stack/#stack-inicial","title":"Stack Inicial","text":""},{"location":"projetos/athena_stack/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>O projeto Athena \u00e9 um projeto de evolu\u00e7\u00e3o de uma stack de dados. A stack de dados \u00e9 um conjunto de ferramentas e tecnologias que s\u00e3o utilizadas para a ingest\u00e3o, armazenamento, processamento e visualiza\u00e7\u00e3o de dados. A stack de dados inicial ser\u00e1 baseada na que muitas empresas usam no seu dia a dia e a mesma que muitos profissionais de dados aprendem a utilizar. A stack de dados inicial \u00e9 composta por:</p> <ul> <li><code>Excel</code> como origem de dados;</li> <li><code>Power Query</code> como ferramenta de ingest\u00e3o de dados;</li> <li><code>Power Query</code> como ferramenta de transforma\u00e7\u00e3o de dados;</li> <li><code>Power Query</code> como ferramenta de carga de dados;</li> <li><code>Power BI</code> como ferramenta de visualiza\u00e7\u00e3o de dados.</li> </ul> <p></p>"},{"location":"projetos/athena_stack/#desvantagens","title":"Desvantagens","text":"<p>Apesar dessa ser na maioria das vezes a stack de dados inicial de muitas empresas e analistas de dados, ela possui algumas desvantagens:</p> <ul> <li> <p>Excel como origem de dados: O Excel \u00e9 uma ferramenta muito poderosa e vers\u00e1til, mas n\u00e3o \u00e9 a melhor ferramenta para armazenar dados. O Excel n\u00e3o \u00e9 um banco de dados e n\u00e3o foi feito para armazenar grandes volumes de dados. Al\u00e9m disso, o Excel n\u00e3o \u00e9 uma ferramenta colaborativa, o que dificulta o compartilhamento de dados entre os membros da equipe.</p> </li> <li> <p>Power Query como ferramenta de ingest\u00e3o de dados: O Power Query \u00e9 uma ferramenta muito poderosa e vers\u00e1til, mas n\u00e3o \u00e9 a melhor ferramenta para a ingest\u00e3o de dados. O Power Query n\u00e3o foi feito para lidar com grandes volumes de dados e n\u00e3o \u00e9 uma ferramenta colaborativa.</p> </li> <li> <p>Power Query como ferramenta de transforma\u00e7\u00e3o de dados: Apesar de ter bastante poder de transforma\u00e7\u00e3o de dados e ser f\u00e1cil de usar, o Power Query n\u00e3o \u00e9 a melhor ferramenta para a transforma\u00e7\u00e3o de dados. O mesmo n\u00e3o foi feito para lidar com grandes volumes de dados al\u00e9m de n\u00e3o possuir versionamento de c\u00f3digo, deixar todo o processo na ferramenta e n\u00e3o permitir a reutiliza\u00e7\u00e3o de c\u00f3digo. Tudo isso gera uma divida t\u00e9cnica muito grande, para o time de dados.</p> </li> <li> <p>Power Query como ferramenta de carga de dados: O Power Query n\u00e3o \u00e9 a melhor ferramenta para a carga de dados.</p> </li> <li> <p>Power BI como ferramenta de visualiza\u00e7\u00e3o de dados: O Power BI \u00e9 uma ferramenta muito poderosa e vers\u00e1til para a visualiza\u00e7\u00e3o de dados, e \u00e9 ai que ele deve ser utilizado.</p> </li> </ul>"},{"location":"projetos/athena_stack/#evolucao-nivel-1","title":"Evolu\u00e7\u00e3o - Nivel 1","text":"<p>A stack de dados evolu\u00edda \u00e9 composta por:</p> <ul> <li><code>Excel</code> como origem de dados;</li> <li><code>Apache Hop</code> como ferramenta de ingest\u00e3o de dados;</li> <li><code>PostgreSQL</code> como banco de dados (Data Warehouse);</li> <li><code>Apache Hop</code> como ferramenta de transforma\u00e7\u00e3o de dados;</li> <li><code>Apache Hop</code> como ferramenta de carga de dados;</li> <li><code>Power BI</code> como ferramenta de visualiza\u00e7\u00e3o de dados.</li> </ul> <p></p>"},{"location":"projetos/athena_stack/#vantagens","title":"Vantagens","text":"<p>A stack de dados evolu\u00edda possui v\u00e1rias vantagens em rela\u00e7\u00e3o a stack de dados inicial:</p> <ul> <li> <p>Excel como origem de dados: O Excel \u00e9 uma ferramenta muito poderosa e vers\u00e1til, e \u00e9 muito utilizada como origem de dados. A stack de dados evolu\u00edda mant\u00e9m o Excel como origem de dados, mas utiliza o Apache Hop para fazer a ingest\u00e3o dos dados.</p> </li> <li> <p>Apache Hop como ferramenta de ingest\u00e3o de dados: O Apache Hop \u00e9 uma ferramenta muito poderosa e vers\u00e1til para a ingest\u00e3o de dados. O Apache Hop foi feito para lidar com grandes volumes de dados e \u00e9 uma ferramenta colaborativa.</p> </li> <li> <p>PostgreSQL como banco de dados (Data Warehouse): O PostgreSQL \u00e9 um banco de dados muito poderoso e vers\u00e1til, e \u00e9 muito utilizado como Data Warehouse. O PostgreSQL foi feito para lidar com grandes volumes de dados e \u00e9 uma ferramenta colaborativa.</p> </li> <li> <p>Apache Hop como ferramenta de transforma\u00e7\u00e3o de dados: O Apache Hop \u00e9 uma ferramenta muito poderosa e vers\u00e1til para a transforma\u00e7\u00e3o de dados. O Apache Hop foi feito para lidar com grandes volumes de dados e possui versionamento de c\u00f3digo, permitindo a reutiliza\u00e7\u00e3o de c\u00f3digo.</p> </li> <li> <p>Apache Hop como ferramenta de carga de dados: O Apache Hop \u00e9 uma ferramenta muito poderosa e vers\u00e1til para a carga de dados.</p> </li> <li> <p>Power BI como ferramenta de visualiza\u00e7\u00e3o de dados: O Power BI \u00e9 uma ferramenta muito poderosa e vers\u00e1til para a visualiza\u00e7\u00e3o de dados, e \u00e9 ai que ele deve ser utilizado.</p> </li> </ul>"},{"location":"projetos/athena_stack/#n1-youtube","title":"| N1 | YouTube","text":"<ul> <li>Projeto Athena - Aula 01 - Introdu\u00e7\u00e3o</li> </ul>"},{"location":"projetos/athena_stack/#arquivos-nivel-1","title":"Arquivos - N\u00edvel 1","text":"<p>Base de dados de Exemplo</p>"},{"location":"projetos/athena_stack/#conclusao-nivel-1","title":"Conclus\u00e3o - N\u00edvel 1","text":"<p>A stack de dados evolu\u00edda \u00e9 muito mais robusta e poderosa do que a inicial, capaz de processar maiores volumes de dados de forma eficiente e colaborativa.</p> <p>N\u00e3o mudamos s\u00f3 as ferramentas, mas tamb\u00e9m a forma de pensar e trabalhar com dados. A stack de dados evolu\u00edda \u00e9 baseada em conceitos de DataOps e Data Engineering, que s\u00e3o fundamentais para a constru\u00e7\u00e3o de pipelines de dados eficientes e escal\u00e1veis.</p> <p>Por\u00e9m como mencionamos essa n\u00e3o \u00e9 a stack definitiva, ela \u00e9 apenas o primeiro passo de uma longa jornada de evolu\u00e7\u00e3o de dados. Por conta disso temos algumas oportunidades de melhoria que ser\u00e3o abordadas nas pr\u00f3ximas evolu\u00e7\u00f5es:</p> <ul> <li> <p>\ud83d\uddd2\ufe0f Excel como origem de dados: Apesar de termos criado valida\u00e7\u00f5es, ainda \u00e9 poss\u00edvel que os usu\u00e1rios do Excel fa\u00e7am altera\u00e7\u00f5es indevidas nos dados. O que torna o processo de ingest\u00e3o de dados vulner\u00e1vel a erros. A melhor abordagem seria a substitui\u00e7\u00e3o do Excel por um banco de dados relacional, uma API ou um sistema de mensageria.</p> </li> <li> <p>\ud83e\uddba Modelagem de dados no Apache Hop: Apesar de termos criado um Data Warehouse no PostgreSQL, a modelagem de dados no Apache Hop ainda \u00e9 um ponto de aten\u00e7\u00e3o, pois estamos usando c\u00f3digos SQL dentro da ferramenta, o que causa transtornos na hora da manuten\u00e7\u00e3o, versionamento e reutiliza\u00e7\u00e3o de c\u00f3digo. A melhor abordagem seria a utiliza\u00e7\u00e3o de ferramentas de modelagem de dados como o dbt.</p> </li> <li> <p>\ud83d\udd12 Seguran\u00e7a dos dados: A seguran\u00e7a dos dados \u00e9 um ponto cr\u00edtico em qualquer stack de dados. A stack de dados evolu\u00edda n\u00e3o possui nenhum mecanismo de seguran\u00e7a dos dados, o que pode ser um problema em ambientes de produ\u00e7\u00e3o. A melhor abordagem seria a implementa\u00e7\u00e3o de mecanismos de seguran\u00e7a dos dados como criptografia, controle de acesso e auditoria.</p> </li> <li> <p>\ud83d\udcca Monitoramento e alertas: O monitoramento e alertas s\u00e3o fundamentais para garantir a integridade e disponibilidade dos dados. A stack de dados evolu\u00edda n\u00e3o possui nenhum mecanismo de monitoramento e alertas. A melhor abordagem seria a implementa\u00e7\u00e3o de mecanismos de monitoramento e alertas como dashboards, alertas por e-mail e integra\u00e7\u00e3o com ferramentas de monitoramento.</p> </li> <li> <p>\ud83c\udfbc Orquestra\u00e7\u00e3o de pipelines de dados: A orquestra\u00e7\u00e3o de pipelines de dados \u00e9 fundamental para garantir a execu\u00e7\u00e3o dos pipelines de forma eficiente e escal\u00e1vel. A stack de dados evolu\u00edda n\u00e3o possui nenhum mecanismo de orquestra\u00e7\u00e3o de pipelines de dados. A melhor abordagem seria a implementa\u00e7\u00e3o de mecanismos de orquestra\u00e7\u00e3o de pipelines de dados como Apache Airflow ou Prefect.</p> </li> <li> <p>\ud83d\udda5\ufe0f Ambiente local: A stack de dados evolu\u00edda foi constru\u00edda em um ambiente local, o que pode tornar o ambiente inst\u00e1vel, pois todas as etapas v\u00e3o depender do poder de processamento da maquina local. A melhor abordagem seria a implementa\u00e7\u00e3o da stack de dados em um ambiente de nuvem como AWS, GCP ou Azure.</p> </li> <li> <p>\ud83e\udec5 Governan\u00e7a de dados: A governan\u00e7a de dados \u00e9 fundamental para garantir a qualidade e integridade dos dados. A stack de dados evolu\u00edda n\u00e3o possui nenhum mecanismo de governan\u00e7a de dados. A melhor abordagem seria a implementa\u00e7\u00e3o de mecanismos de governan\u00e7a de dados como cat\u00e1logo de dados, gloss\u00e1rio de dados e pol\u00edticas de dados.</p> </li> <li> <p>\u2328\ufe0f Testes automatizados: Os testes automatizados s\u00e3o fundamentais para garantir a qualidade e integridade dos dados. A stack de dados evolu\u00edda n\u00e3o possui nenhum mecanismo de testes automatizados. A melhor abordagem seria a implementa\u00e7\u00e3o de mecanismos de testes automatizados como testes de integra\u00e7\u00e3o, testes de unidade e testes de regress\u00e3o.</p> </li> <li> <p>\ud83d\udc69\u200d\ud83c\udfeb Documenta\u00e7\u00e3o dos processos: A documenta\u00e7\u00e3o dos processos \u00e9 fundamental para garantir a qualidade e integridade dos dados. A stack de dados evolu\u00edda n\u00e3o possui nenhum mecanismo de documenta\u00e7\u00e3o dos processos. A melhor abordagem seria a implementa\u00e7\u00e3o de mecanismos de documenta\u00e7\u00e3o dos processos como documenta\u00e7\u00e3o de c\u00f3digo, documenta\u00e7\u00e3o de pipelines e documenta\u00e7\u00e3o de datasets.</p> </li> </ul> <p>A perfei\u00e7\u00e3o \u00e9 inating\u00edvel, mas a melhoria \u00e9 infinita. A stack de dados evolu\u00edda \u00e9 um grande avan\u00e7o em rela\u00e7\u00e3o a stack de dados inicial, mas ainda h\u00e1 muito a ser feito para torn\u00e1-la ainda mais robusta e poderosa. A stack de dados evolu\u00edda \u00e9 apenas o primeiro passo de uma longa jornada de evolu\u00e7\u00e3o de dados, e estamos apenas come\u00e7ando, aguardem os pr\u00f3ximos n\u00edveis.</p>"},{"location":"projetos/athena_stack/#evolucao-nivel-2","title":"Evolu\u00e7\u00e3o - Nivel 2","text":"<p>A stack de dados evolu\u00edda n\u00edvel 2 \u00e9 composta pelas seguintes melhorias:</p> <ul> <li><code>Banco de dados relacional</code> como origem de dados;</li> <li><code>GitHub</code> integrado com <code>Apache Hop</code>;</li> <li>Data Warehouse rodando no <code>Linux (Docker)</code>;</li> <li><code>Data Warehouse</code> aberto a conex\u00f5es externas;</li> <li>N\u00edveis de acesso no <code>DW PostgreSQL</code>;</li> <li>Pipelines do <code>Apache Hop</code> Orquestrados;</li> </ul> <p></p>"},{"location":"projetos/athena_stack/#vantagens_1","title":"Vantagens","text":"<p>A stack de dados evolu\u00edda n\u00edvel 2 possui v\u00e1rias vantagens em rela\u00e7\u00e3o a stack n\u00edvel 1:</p> <ul> <li> <p>Banco de dados relacional como origem de dados: O banco de dados relacional \u00e9 uma fonte de dados mais robusta e segura do que o Excel. O banco de dados relacional possui mecanismos de seguran\u00e7a e integridade dos dados que o Excel n\u00e3o possui.</p> </li> <li> <p>GitHub integrado com Apache Hop: O GitHub \u00e9 uma ferramenta muito poderosa e vers\u00e1til para o versionamento de c\u00f3digo. O GitHub permite o controle de vers\u00e3o do c\u00f3digo, o que facilita a colabora\u00e7\u00e3o entre os membros da equipe.</p> </li> <li> <p>Data Warehouse rodando no Linux (Docker): O Data Warehouse rodando no Linux (Docker) \u00e9 mais est\u00e1vel e seguro do que o Data Warehouse rodando no Windows. O Linux \u00e9 um sistema operacional mais robusto e seguro, e o Docker \u00e9 uma ferramenta muito poderosa e vers\u00e1til para a execu\u00e7\u00e3o de containers.</p> </li> <li> <p>Data Warehouse aberto a conex\u00f5es externas: O Data Warehouse aberto a conex\u00f5es externas permite que outras ferramentas e sistemas se conectem ao Data Warehouse. O Data Warehouse aberto a conex\u00f5es externas facilita a integra\u00e7\u00e3o autom\u00e1tica Power BI, Tableau, Metabase, etc.</p> </li> <li> <p>N\u00edveis de acesso no DW PostgreSQL: Os n\u00edveis de acesso no Data Warehouse PostgreSQL permitem controlar quem pode acessar e modificar os dados. Os n\u00edveis de acesso garantem a seguran\u00e7a e integridade dos dados.</p> </li> <li> <p>Pipelines do Apache Hop orquestrados: Os pipelines do Apache Hop orquestrados garantem a execu\u00e7\u00e3o dos pipelines de forma eficiente e escal\u00e1vel. Os pipelines orquestrados permitem a execu\u00e7\u00e3o dos pipelines em paralelo e em sequ\u00eancia, tornando as cargas autom\u00e1ticas e escal\u00e1veis.</p> </li> </ul>"},{"location":"projetos/athena_stack/#n2-youtube","title":"| N2 | YouTube","text":"<ul> <li>Projeto Athena - Aula 01 - Introdu\u00e7\u00e3o</li> </ul>"},{"location":"projetos/athena_stack/#conclusao-nivel-2","title":"Conclus\u00e3o - N\u00edvel 2","text":"<p>A stack de dados evolu\u00edda n\u00edvel 2 \u00e9 um grande avan\u00e7o em rela\u00e7\u00e3o a stack de dados evolu\u00edda n\u00edvel 1, capaz de processar maiores volumes de dados de forma eficiente e colaborativa.</p> <p>Por\u00e9m como mencionamos essa n\u00e3o \u00e9 a stack definitiva, ela \u00e9 apenas o segundo passo de uma longa jornada de evolu\u00e7\u00e3o de dados. Por conta disso temos algumas oportunidades de melhoria que ser\u00e3o abordadas nas pr\u00f3ximas evolu\u00e7\u00f5es:</p> <ul> <li> <p>\ud83d\uddd2\ufe0f Banco de dados relacional como origem de dados: Apesar de termos substitu\u00eddo o Excel por um banco de dados relacional, utilizamos um banco que subimos dentro do pr\u00f3prio ambiente. Vamos melhorar isso no futuro buscando de uma API.</p> </li> <li> <p>\ud83e\uddba Modelagem de dados no Apache Hop: Apesar de termos criado um Data Warehouse no PostgreSQL, a modelagem de dados no Apache Hop ainda \u00e9 um ponto de aten\u00e7\u00e3o, pois estamos usando c\u00f3digos SQL dentro da ferramenta, o que causa transtornos na hora da manuten\u00e7\u00e3o, versionamento e reutiliza\u00e7\u00e3o de c\u00f3digo. A melhor abordagem seria a utiliza\u00e7\u00e3o de ferramentas de modelagem de dados como o dbt.</p> </li> <li> <p>\ud83d\udd12 Seguran\u00e7a dos dados: A seguran\u00e7a dos dados \u00e9 um ponto cr\u00edtico em qualquer stack de dados. A stack de dados evolu\u00edda n\u00edvel 2 possui apenas um mecanismo de seguran\u00e7a dos dados, o que pode ser um problema em ambientes de produ\u00e7\u00e3o. A melhor abordagem seria a implementa\u00e7\u00e3o de mecanismos de seguran\u00e7a dos dados como criptografia, controle de acesso e auditoria.</p> </li> <li> <p>\ud83d\udcca Monitoramento e alertas: O monitoramento e alertas s\u00e3o fundamentais para garantir a integridade e disponibilidade dos dados. A stack de dados evolu\u00edda n\u00edvel 2 n\u00e3o possui nenhum mecanismo de monitoramento e alertas. A melhor abordagem seria a implementa\u00e7\u00e3o de mecanismos de monitoramento e alertas como dashboards, alertas por e-mail e integra\u00e7\u00e3o com ferramentas de monitoramento.</p> </li> <li> <p>\ud83d\udda5\ufe0f Ambiente local: A stack de dados evolu\u00edda n\u00edvel 2 foi constru\u00edda em um ambiente local, o que pode tornar o ambiente inst\u00e1vel, pois todas as etapas v\u00e3o depender do poder de processamento da maquina local. A melhor abordagem seria a implementa\u00e7\u00e3o da stack de dados em um ambiente de nuvem como AWS, GCP ou Azure.</p> </li> <li> <p>\ud83e\udec5 Governan\u00e7a de dados: A governan\u00e7a de dados \u00e9 fundamental para garantir a qualidade e integridade dos dados. A stack de dados evolu\u00edda n\u00edvel 2 n\u00e3o possui nenhum mecanismo de governan\u00e7a de dados. A melhor abordagem seria a implementa\u00e7\u00e3o de mecanismos de governan\u00e7a de dados como cat\u00e1logo de dados, gloss\u00e1rio de dados e pol\u00edticas de dados.</p> </li> <li> <p>\u2328\ufe0f Testes automatizados: Os testes automatizados s\u00e3o fundamentais para garantir a qualidade e integridade dos dados. A stack de dados evolu\u00edda n\u00edvel 2 n\u00e3o possui nenhum mecanismo de testes automatizados. A melhor abordagem seria a implementa\u00e7\u00e3o de mecanismos de testes automatizados como testes de integra\u00e7\u00e3o, testes de unidade e testes de regress\u00e3o.</p> </li> <li> <p>\ud83d\udc69\u200d\ud83c\udfeb Documenta\u00e7\u00e3o dos processos: A documenta\u00e7\u00e3o dos processos \u00e9 fundamental para garantir a qualidade e integridade dos dados. A stack de dados evolu\u00edda n\u00edvel 2 n\u00e3o possui nenhum mecanismo de documenta\u00e7\u00e3o dos processos. A melhor abordagem seria a implementa\u00e7\u00e3o de mecanismos de documenta\u00e7\u00e3o dos processos como documenta\u00e7\u00e3o de c\u00f3digo, documenta\u00e7\u00e3o de pipelines e documenta\u00e7\u00e3o de datasets.</p> </li> </ul> <p>A perfei\u00e7\u00e3o \u00e9 inating\u00edvel, mas a melhoria \u00e9 infinita. A stack de dados evolu\u00edda n\u00edvel 2 \u00e9 um grande avan\u00e7o em rela\u00e7\u00e3o a stack de dados evolu\u00edda n\u00edvel 1, mas ainda h\u00e1 muito a ser feito para torn\u00e1-la ainda mais robusta e poderosa. A stack de dados evolu\u00edda n\u00edvel 2 \u00e9 apenas o segundo passo de uma longa jornada de evolu\u00e7\u00e3o de dados, e estamos apenas come\u00e7ando, aguardem os pr\u00f3ximos n\u00edveis.</p>"},{"location":"projetos/athena_stack/#stack-de-dados-evoluida-nivel-3","title":"Stack de Dados Evolu\u00edda - Nivel 3","text":"<p>A stack de dados evolu\u00edda n\u00edvel 3 \u00e9 composta pelas seguintes melhorias:</p> <ul> <li><code>API</code> como origem de dados;</li> <li><code>Airbyte</code> para ingest\u00e3o de dados;</li> <li><code>Apache Airflow</code> para orquestra\u00e7\u00e3o de pipelines;</li> <li><code>DBT</code> para modelagem de dados;</li> <li><code>DBT</code> para governan\u00e7a de dados;</li> <li><code>DBT</code> para documenta\u00e7\u00e3o de processos;</li> <li><code>DBT</code> para testes automatizados;</li> <li><code>DBT</code> qualidade de dados;</li> <li><code>Postgres</code> como Data Warehouse;</li> <li><code>Metabase</code> para visualiza\u00e7\u00e3o de dados;</li> <li><code>Grafana</code> para monitoramento de Infraestrutura;</li> <li><code>Prometheus</code> para monitoramento de Aplica\u00e7\u00f5es;</li> <li><code>Cadvisor</code> para monitoramento de Containers;</li> <li><code>Docker</code> para orquestra\u00e7\u00e3o de containers;</li> <li><code>Linux</code> como sistema operacional;</li> <li><code>GIT</code> para versionamento de c\u00f3digo;</li> <li><code>Shell Script</code> para automa\u00e7\u00e3o de tarefas;</li> </ul> <p></p>"},{"location":"projetos/athena_stack/#vantagens_2","title":"Vantagens","text":"<p>A stack de dados evolu\u00edda n\u00edvel 3 oferece diversas vantagens em compara\u00e7\u00e3o \u00e0 stack n\u00edvel 2, com ferramentas especializadas que aprimoram cada aspecto do processamento de dados:</p> <p>API como origem de dados: A API (Application Programming Interface) \u00e9 utilizada como fonte de dados, oferecendo <code>robustez</code> e <code>seguran\u00e7a</code> superior aos bancos de dados relacionais tradicionais. APIs permitem a <code>integra\u00e7\u00e3o</code> com sistemas externos, facilitam o acesso controlado aos dados e garantem a <code>integridade</code> das transa\u00e7\u00f5es atrav\u00e9s de <code>autentica\u00e7\u00e3o</code>, <code>autoriza\u00e7\u00e3o</code> e <code>mecanismos de criptografia</code>.</p> <p>Airbyte para ingest\u00e3o de dados: O Airbyte \u00e9 uma ferramenta <code>open-source</code> projetada para a ingest\u00e3o de grandes volumes de dados de <code>diversas fontes</code>. Ele oferece conectores <code>pr\u00e9-constru\u00eddos</code> para v\u00e1rias origens de dados, permite a configura\u00e7\u00e3o de pipelines de dados de maneira <code>colaborativa</code> e suporta funcionalidades como <code>replica\u00e7\u00e3o incremental</code>, transforma\u00e7\u00e3o de dados e <code>monitoramento cont\u00ednuo dos fluxos de ingest\u00e3o</code>.</p> <p>Apache Airflow para orquestra\u00e7\u00e3o de pipelines: O Apache Airflow \u00e9 uma plataforma poderosa para a <code>orquestra\u00e7\u00e3o</code> de workflows complexos de dados. Ele permite a defini\u00e7\u00e3o, <code>agendamento</code> e <code>monitoramento</code> de pipelines de dados atrav\u00e9s de <code>DAGs</code> (Directed Acyclic Graphs), facilitando o gerenciamento de depend\u00eancias entre tarefas, a <code>escalabilidade</code> e o monitoramento em tempo real com <code>alertas</code> configur\u00e1veis.</p> <p>DBT (Data Build Tool) para modelagem, governan\u00e7a e qualidade de dados: O DBT \u00e9 uma ferramenta central na stack n\u00edvel 3, abrangendo v\u00e1rias fun\u00e7\u00f5es cr\u00edticas:</p> <ul> <li> <p>Modelagem de dados: Facilita a transforma\u00e7\u00e3o de dados utilizando <code>SQL</code>, promovendo a <code>reutiliza\u00e7\u00e3o</code> e <code>versionamento</code> de c\u00f3digo, al\u00e9m de gerar <code>documenta\u00e7\u00e3o</code> autom\u00e1tica e vis\u00edvel atrav\u00e9s de uma interface web.</p> </li> <li> <p>Governan\u00e7a de dados: Oferece recursos como <code>cat\u00e1logo de dados e gloss\u00e1rio</code>, ajudando na defini\u00e7\u00e3o de pol\u00edticas de dados e na organiza\u00e7\u00e3o de ativos de dados de maneira estruturada.</p> </li> <li> <p>Qualidade de dados: Implementa <code>testes automatizados</code> para valida\u00e7\u00e3o, limpeza e enriquecimento de dados, garantindo a <code>precis\u00e3o e confiabilidade dos datasets</code>.</p> </li> </ul> <p>Postgres como Data Warehouse: O PostgreSQL \u00e9 utilizado como um banco de dados Data Warehouse devido \u00e0 sua <code>robustez</code> e capacidade de lidar com grandes volumes de dados. Ele oferece suporte a transa\u00e7\u00f5es <code>ACID</code>, \u00edndices avan\u00e7ados, replica\u00e7\u00e3o e ferramentas de backup, al\u00e9m de extens\u00f5es que melhoram seu desempenho para cargas de trabalho anal\u00edticas.</p> <p>Metabase para visualiza\u00e7\u00e3o de dados: O Metabase \u00e9 uma ferramenta de BI (Business Intelligence) que permite a cria\u00e7\u00e3o de <code>dashboards interativos</code>, gr\u00e1ficos e relat\u00f3rios. Ele suporta consultas <code>SQL</code>, visualiza\u00e7\u00e3o de dados em <code>tempo real</code> e colabora\u00e7\u00e3o entre usu\u00e1rios atrav\u00e9s de compartilhamento de pain\u00e9is.</p> <p>Grafana para monitoramento de infraestrutura: O Grafana \u00e9 uma plataforma <code>open-source</code> que oferece visualiza\u00e7\u00e3o e an\u00e1lise de <code>m\u00e9tricas de infraestrutura</code>. Ele integra-se com diversas fontes de dados, permitindo a cria\u00e7\u00e3o de dashboards personalizados e <code>alertas</code> para monitoramento proativo da <code>sa\u00fade da infraestrutura</code>.</p> <p>Prometheus para monitoramento de aplica\u00e7\u00f5es: O Prometheus \u00e9 uma ferramenta de monitoramento e alerta de c\u00f3digo aberto focada em aplica\u00e7\u00f5es. Ele coleta e armazena m\u00e9tricas em <code>s\u00e9ries temporais</code>, suporta consultas avan\u00e7adas com <code>PromQL (Prometheus Query Language)</code> e integra-se nativamente com Grafana para visualiza\u00e7\u00e3o.</p> <p>Cadvisor para monitoramento de containers: O Cadvisor (Container Advisor) monitora o uso de recursos <code>(CPU, mem\u00f3ria, rede e I/O)</code> dos containers em <code>tempo real</code>, fornecendo m\u00e9tricas detalhadas que ajudam na otimiza\u00e7\u00e3o e gerenciamento de ambientes <code>containerizados</code>.</p> <p>Docker para gerenciamento de containers: O Docker permite a cria\u00e7\u00e3o, implanta\u00e7\u00e3o e gerenciamento de containers de forma <code>eficiente</code>. Ele isola aplica\u00e7\u00f5es em ambientes separados, facilita a <code>escalabilidade horizontal</code> e integra-se com ferramentas de <code>CI/CD</code> e monitoramento para automa\u00e7\u00e3o completa do ciclo de vida das aplica\u00e7\u00f5es.</p> <p>Linux como sistema operacional: O Linux \u00e9 amplamente utilizado devido \u00e0 sua <code>estabilidade</code>, <code>seguran\u00e7a</code> e <code>flexibilidade</code>. Ele oferece suporte a scripts de automa\u00e7\u00e3o, ferramentas de gerenciamento de pacotes e um ecossistema robusto de <code>software livre</code>, essencial para a execu\u00e7\u00e3o <code>confi\u00e1vel</code> de pipelines de dados.</p> <p>GIT para versionamento de c\u00f3digo: O GIT \u00e9 uma ferramenta de controle de vers\u00e3o <code>distribu\u00edda</code> que facilita o rastreamento de mudan\u00e7as no c\u00f3digo, <code>colabora\u00e7\u00e3o entre desenvolvedores</code> e manuten\u00e7\u00e3o de um hist\u00f3rico completo de altera\u00e7\u00f5es, essencial para projetos de dados <code>complexos</code>.</p> <p>Shell Script para automa\u00e7\u00e3o de tarefas: Shell Scripts s\u00e3o utilizados para automatizar tarefas <code>repetitivas</code> e complexas, integrando diversos processos e ferramentas. Eles s\u00e3o altamente <code>eficientes</code> para a execu\u00e7\u00e3o de scripts de manuten\u00e7\u00e3o, backups, deploys e outras opera\u00e7\u00f5es administrativas, suportando a <code>escalabilidade</code> e a <code>integra\u00e7\u00e3o</code> com sistemas de monitoramento.</p> <p>Essa stack n\u00edvel 3, composta por ferramentas especializadas, proporciona uma infraestrutura de dados robusta, segura e eficiente, capaz de lidar com grandes volumes de dados e complexidades operacionais, garantindo alto desempenho e confiabilidade em todas as etapas do pipeline de dados.</p>"},{"location":"projetos/athena_stack/#n3-youtube","title":"| N3 | YouTube","text":"<ul> <li>Projeto Athena - Aula 01 - Introdu\u00e7\u00e3o</li> </ul>"},{"location":"projetos/zero_inadimplencia/","title":"Projeto - Zero Inadimpl\u00eancia","text":""},{"location":"projetos/zero_inadimplencia/#projeto-zero-inadimplencia-em-andamento","title":"Projeto Zero Inadimpl\u00eancia - Em andamento","text":"<p>Reposit\u00f3rio do Projeto</p>"},{"location":"projetos/zero_inadimplencia/#descricao","title":"Descri\u00e7\u00e3o","text":"<p>Esse projeto tem como objetivo desenvolver um sistema de controle de inadimpl\u00eancia para uma empresa.</p> <p>Ele demonstra as habilidades de <code>desenvolvimento de ETL</code>, <code>modelagem de dados</code>, <code>desenvolvimento de dashboards</code> e <code>desenvolvimento de automa\u00e7\u00f5es</code>.</p>"},{"location":"projetos/zero_inadimplencia/#solicitacao-do-cliente","title":"Solicita\u00e7\u00e3o do cliente","text":"<p>O cliente est\u00e1 enfrentando problemas com a inadimpl\u00eancia na sua empresa, e gostaria de ter um controle mais efetivo sobre isso.</p> <p>Ele n\u00e3o possui nenhum controle sobre a inadimpl\u00eancia, e gostaria de ter um dashboard para poder visualizar os clientes inadimplentes, m\u00e9tricas sobre a inadimpl\u00eancia e sobre a equipe de cobran\u00e7a.</p> <p>Ele gostaria tamb\u00e9m de enviar alertas para a equipe de cobran\u00e7a, para que eles possam agir rapidamente e evitar que a inadimpl\u00eancia aumente.</p> <p>Enviar aos clientes, por e-mail, alertas sobre a inadimpl\u00eancia e 5 dias antes das faturas vencerem, para que eles possam regularizar a situa\u00e7\u00e3o.</p>"},{"location":"projetos/zero_inadimplencia/#solucao","title":"Solu\u00e7\u00e3o","text":"<ul> <li> <p>Desenvolver um ETL para extrair os dados de inadimpl\u00eancia, transformar e carregar em um banco de dados.</p> </li> <li> <p>Desenvolver um dashboard para visualiza\u00e7\u00e3o dos dados com m\u00e9tricas sobre a inadimpl\u00eancia e sobre a equipe de cobran\u00e7a.</p> </li> <li> <p>Desenvolver um rob\u00f4 para enviar alertas para a equipe de cobran\u00e7a e para os clientes.</p> </li> </ul>"},{"location":"projetos/zero_inadimplencia/#arquitetura-do-projeto","title":"Arquitetura do Projeto","text":""},{"location":"projetos/zero_inadimplencia/#tecnologias-utilizadas","title":"Tecnologias Utilizadas","text":""},{"location":"projetos/zero_inadimplencia/#aulas-youtube","title":"Aulas Youtube","text":"<ul> <li>V\u00eddeo Parte 1 - Introdu\u00e7\u00e3o</li> <li>V\u00eddeo Parte 2 - Preparando Ambiente</li> <li>V\u00eddeo Parte 3 - Extraindo Excel para o Banco de Dados</li> <li>V\u00eddeo PArte 4 - Modelagem de dados SQL no Apache Hop</li> <li>V\u00eddeo Parte 5 - Criando Dashboards no Power BI - Parte 1</li> <li>V\u00eddeo Parte 6 - Criando Dashboards no Power BI - Parte 2</li> </ul>"}]}